@software{Jakobi2025_MultiplEYE,
  author  = {Jakobi, Deborah N. and
             Filip, Maroš and
             Ding, Cui and
             J{\"a}ger, Lena A.},
  title   = {{MultiplEYE Image Generation Software}},
  year    = {2025},
  date    = {2025-03-25},
  url     = {https://github.com/theDebbister/wg1-image-creation/},
  note    = {If you use this software, please cite it as below.},
  version = {1.0},
  type    = {Computer software}
}

@software{MultiplEYE_ExperimentImplementation2025,
  author = {},
  title  = {{MultiplEYE Experiment implementation Software}},
  year   = {2025},
  url    = {https://github.com/MultiplEYE-COST/wg1-experiment-implementation},
  type   = {Computer software}
}

@manual{EyeLink1000PlusUserManual,
  author  = {SR Research},
  title   = {EyeLink® 1000 Plus User Manual},
  version = {1.0.17}
}

@inproceedings{Krakowczyk2023_pymovements,
  author    = {Krakowczyk, Daniel G. and Reich, David R. and Chwastek, Jakob and
               Jakobi, Deborah N. and Prasse, Paul and S{\"u}{\ss}, Assunta and
               Turuta, Oleksii and Kasprowski, Pawe{\l} and J{\"a}ger, Lena A.},
  title     = {{pymovements}: A Python Package for Processing Eye Movement Data},
  booktitle = {Proceedings of the 2023 Symposium on Eye Tracking Research and Applications ({ETRA} '23)},
  year      = {2023},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3588015.3590134},
  url       = {https://doi.org/10.1145/3588015.3590134},
  isbn      = {979-8-4007-0150-4},
  location  = {T{\"u}bingen, Germany},
  series    = {ETRA '23}
}

@inproceedings{hollenstein-etal-2021-multilingual,
  title     = {Multilingual Language Models Predict Human Reading Behavior},
  author    = {Hollenstein, Nora  and
               Pirovano, Federico  and
               Zhang, Ce  and
               J{\"a}ger, Lena  and
               Beinborn, Lisa},
  editor    = {Toutanova, Kristina  and
               Rumshisky, Anna  and
               Zettlemoyer, Luke  and
               Hakkani-Tur, Dilek  and
               Beltagy, Iz  and
               Bethard, Steven  and
               Cotterell, Ryan  and
               Chakraborty, Tanmoy  and
               Zhou, Yichao},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.naacl-main.10/},
  doi       = {10.18653/v1/2021.naacl-main.10},
  pages     = {106--123},
  abstract  = {We analyze if large language models are able to predict patterns of human reading behavior. We compare the performance of language-specific and multilingual pretrained transformer models to predict reading time measures reflecting natural human sentence processing on Dutch, English, German, and Russian texts. This results in accurate models of human reading behavior, which indicates that transformer models implicitly encode relative importance in language in a way that is comparable to human processing mechanisms. We find that BERT and XLM models successfully predict a range of eye tracking features. In a series of experiments, we analyze the cross-domain and cross-language abilities of these models and show how they reflect human sentence processing.}
}

@unknown{Simplification_LSBert,
  author = {Qiang, Jipeng and Li, Yun and Zhu, Yi and Yuan, Yun-Hao and Wu, Xindong},
  year   = {2020},
  month  = {06},
  pages  = {},
  title  = {LSBert: A Simple Framework for Lexical Simplification},
  doi    = {10.48550/arXiv.2006.14939}
}
